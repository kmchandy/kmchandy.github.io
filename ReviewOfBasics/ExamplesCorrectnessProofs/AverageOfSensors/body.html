    <h1 class="w3-text-teal">Self Test: Distributed Averaging</h1>

    <p>
    
    This self test is about analyzing a concurrent system in
    which a collection of agents, each with access to two sensor
    readings, computes the average sensor reading.
    An extension of the problem, given at the end of this page,
    considers a general case in which agents have access to arbitrary
    subsets of sensor readings. Later sections describe algorithms in
    which the state space is continuous and the state evolves over
    continuous time; we use differential equations to represent
    continuous state transions and Lyapunov functions to prove
    progress as opposed to discrete transitions and variant functions.
    <p>

    <h2 class="w3-text-teal">Problem Description</h2>
    
    <p>
    We are given a connected undirected graph in which each vertex represents a
    sensor and each edge represents an agent. Sensor \(j\) reading is
    a scalar
    value \(t_{j}\). Initially the value of \(t_{j}\) is \(t_{j}^{0}\) where \(t_{j}^{0}\)
    is a measurement made by sensor \(j\). The specification of the
    algorithm is that the computation must terminate, and at termination
    each sensor value must approximately equal the average of all the
    sensor readings.

    <p class="w3-text-teal">Specification</p>
    
    We are given a positive constant \(\epsilon\) which determines the
    accuracy of the result.
    Let \(avg(X)\) be the average of the elements of \(X\). The
    specification is that at termination, the following predicates
    must hold, where \(t\) is the vector whose elements are sensor
    readings \(t_{j}\).
</p>
    <ol>
      <li>
      <p>
      \(
      avg(t) = avg(t^{0})
      \)
      </p>
      </li>

      <li>
      <p>
      \(t_{i}\) and \(t_{j}\) are sufficiently close for all edges
      \(i,j\):
      </p>
      <p>
      \(
      \forall \; \textrm{edges} \; (i, j): \; |t_{i} - t_{j}| <
      \epsilon
      \)
      </p>
      </li>
</ol>
</p>

<h3 class="w3-text-teal">Agent Steps</h3>
The shared variables of the system are the sensor readings. The agent
corresponding to an edge \((i, j)\), executes the following guarded
command.
<p>
\(
\textbf{if} \; |t_{i} - t_{j}| \geq \epsilon \; \textbf{then} \;
t_{i} = t_{j} = (t_{i} + t_{j})/2.0
\)
</p>

<p>
In this example, agents have no local variables; agents have no
state.
The state of the system is given by the values of the shared
variables.
Let \(t\) be the vector whose \(j\)-th element is \(t_{j}\). Then the
system state is \(t\).
The timeline diagram consists of lines for each shared
variable.

<h2 class="w3-text-teal">Self Test: Proof of Correctness</h2>
    
    <h5 class="w3-text-teal">Test 1</h5>
    Give and prove an invariant of the loop.
    
    <h5 class="w3-text-teal">Test 2</h5>
    Prove that the loop terminates by giving a variant function for
    the loop. 
    
    <h5 class="w3-text-teal">Test 3</h5>
Show that the specification holds upon termination of the loop.

<h3 class="w3-text-teal">Answers</h3>
   
    <h5 class="w3-text-teal">Answer 1</h5>

There are several examples of invariants and
variant functions. Here is one example.

<p>
The proof of the following invariant is
straightforward.

<h4 class="w3-text-teal">Invariant</h4>

      <p>
      \(
      avg(t) = avg(t^{0})
      \)
</p>

<h4 class="w3-text-teal">Proof of Invariant</h4>

<p class="w3-text-teal">Part 1: Invariant holds Initially</p>
Trivially:
<p>
\(
avg(t^{0}) = avg(t^{0})
\)

<p class="w3-text-teal">Part 2: Invariant is Stable, i.e., it is maintained at
every step</p>
This is obvious because the sum of \(t_{i}, t_{j}\) remains unchanged
when they are replaced by their midpoints. This level of informality
is acceptable.

<p>
For a more formal proof, we will prove the following Hoare triple for all \(i, j\) where the
guard holds. (The triple holds even if the guard is False, but that is
irrelevant.)

<p>
For all \(k\)
<br>
\(
\{t_{i} + t_{j} = k\} \quad t_{i}, t_{j} = avg(t_{i}, t_{j}), avg(t_{i},
t_{j}) \quad \{t_{i} + t_{j} = k\}
\)
<p>
Substitute \(avg(t_{i}, t_{j})\) for \(t_{i}\) and \(t_{j}\) in the
post condition to get the weakest precondition. Therefore the weakest
precondition is:
<p>
\(
avg(t_{i}, t_{j}) + avg(t_{i}, t_{j}) = k
\)
<p>
which simplifies to
<p>
\(
t_{i} + t_{j} = k
\)
<p>
The given precondition implies the weakest precondition (indeed, the
given precondition <i>is</i> the weakest precondition) and so the
Hoare triple holds.



<h4 class="w3-text-teal">Answer 2</h4>
<p>
A variant function \(f\) is:

<p>
\(f \; = \; \sum_{j} t_{j}^{2} /2 \)
</p>
This function has the following properties:
<ol>
  <li>
  It is bounded below
  </li>
  <li>
  An execution of a command with a true guard reduces \(f\) by at
  least \(\epsilon^{2}/2\). So the variant function can decrease in
  only a finite number of steps. Therefore, execution of the algorithm
  terminates. 
  </li>
</ol>

<h4 class="w3-text-teal">Answer 3</h4>
If the invariant holds and all guards are false then the specification
is satisfied: the proof is straightforward.
<p>
A more rigorous proof is as follows. At termination all guards are
false. Therefore, at termination, for all edges \(\{i, j\}\) in the
graph,
<p>
\(
|t_{i} - t_{j}| < \epsilon
\)