<!---------------------------------------------------->
<h1 class="w3-text-teal">Dining Philosophers</h1>
<!---------------------------------------------------->

<h4 class="w3-text-teal">
This module describes algorithms for "The Distributed Dining
Philosophers Problem," a problem that exemplifies mutual exclusion of
critical operations among agents in a distributed setting.
</h4>


This and following modules describe algorithms by which agents manage
conflicts among themselves. This module describes an
    algorithm for a distributed mutual exclusion problem called
    <a href="https://en.wikipedia.org/wiki/Dining_philosophers_problem">
    <i>The Distributed Dining Philosophers Problem</i>
    </a>.

<!---------------------------------------------------->
<h3 class="w3-text-teal">Key Concepts</h3>
    <!---------------------------------------------------->
    
    <h4 class="w3-text-teal">1. Mutual Exclusion</h4>
    The distributed dining philosophers is a generalization of the
    mutual exclusion problem to distributed systems.  A <i>mutual
    exclusion</i> or <i>mutex</i> problem is one in which only one
    agent can carry out some activity such as executing a <i>critical
    section</i> of a program. Mutex algorithms ensure that all agents
    that want to carry out such activities do so eventually. 

    <h4 class="w3-text-teal">2. Priorities among Agents</h4>
    Distributed conflict-resolution algorithms ensure that
    when multiple agents are in a conflict that only one of them can
    win, every agent wins eventually. A
    standard way of managing conflicts is to have agents agree on
    relative priorities among themselves; the agent with higher
    priority wins.

    <p>
    Distributed algorithms often use a good-neighbor policy to ensure
    that all agents win conflicts eventually: <i>An agent that wins a
    conflict makes its priority lower than the priorities of all the
    agents with which it competes.</i>
    
    <h4 class="w3-text-teal">3. Tokens and What Agents Know</h4>
    An agent can resolve a conflict with other agents only if it knows
    something about the states of other agents. For example, what
    agents want to enter a critical section and what are their
priorities?

    <a href="../Knowledge/Knowledge.html">
    What agents know is defined in this module.</a> We used the
    concept of tokens to illustrate what agents know.  A system has a
    fixed number of indivisible tokens which are neither created nor
    destroyed. An agent that holds a token knows that no other agent
    holds that token.  This knowledge is at the core of many conflict
    resolution algorithms.


<!---------------------------------------------------->
<h2 class="w3-text-teal">The Problem</h2>
<!---------------------------------------------------->

<h4 class="w3-text-teal">Agent States in a Mutual Exclusion Problem</h4>
    <figure>
    <img src="Slide02.jpg" alt="Fig2" style="width:100%">
    <figcaption>Fig.2: States in Mutual Exclusion</figcaption>
</figure>

An agent in a mutual exclusion problem is in one of three states:
<ol>
  <li>
  <i>Outside critical section</i>:
  The agent is executing outside its critical section. An agent can remain in this
  state for ever, or it may transit after finite time to the next state: waiting to
  enter its critical section.
  </li>
  <li>
  <i>Waiting to enter critical section</i>:
  The agent waits to enter critical section until it is given
  permission to do so by the operating system.
  </li>
  <li>
  <i>In critical section</i>:
  The agent executes in its critical section.  An agent does not
  remain in its critical section forever. It does so for only
  <i>finite</i> time after which it transits to the state, outside
  critical section.
  </li>
</ol>

<p>
Clients determine transitions from <i>outside critical section</i> to <i>waiting to
enter critical section</i>, and from <i>in critical section</i> to
<i>outside critical section</i>.

The operating system determines transitions from <i>waiting to
enter critical section</i> to <i>outside critical section</i>.


<!----------------------------------------------------------->
<h4 class="w3-text-teal">Agent States in the Dining PhilosophersProblem</h4>
    <figure>
    <img src="Slide03.jpg" alt="Fig3" style="width:100%">
    <figcaption>Fig.3: States in Dining Philosophers</figcaption>
</figure>

The name "Dining Philosophers" is an example of CS humor
(an oxymoron?).
Philosophers may think for ever, but eat for only finite time. The
algorithm must ensure that hungry philosophers don't starve --- they
get to eat <i>eventually</i>.
The problem and its name were proposed by Edsger W. Dijkstra, a CS pioneer.

<p>
The states "Thinking", "Hungry", and "Eating" correspond exactly to
<i>Outside critical section</i>, <i>Waiting to enter critical
section</i>, and <i>In critical section</i>, respectively.


<h3 class="w3-text-teal">Agent Communication Structure</h3>
    <figure>
    <img src="Slide04.jpg" alt="Fig4" style="width:100%">
    <figcaption>Fig.4: Communication among Agents</figcaption>
</figure>

The commununication structure among agents is represented by an
undirected graph in which the nodes are agents and each edge
represents two channels, one in each direction. The agents are either
OS or client agents. There is one client agent associated with each OS
agent. Clients are shown as squares and OS agents as circles.
For example client agent \(w\) is associated with OS agent
\(w\). The diagram does not show all clients so as not to make the
diagram too crowded.

<p>
A pair of OS agents are neighbors when there is an edge between
them. A pair of client agents are neighbors when the OS agents with
which they are associated are neighbors. For example, in the figure, 
\(w\) and \(y\) are neighbors.

<!------------------------------------------------------------->
<h2 class="w3-text-teal">Specification</h2>

<h3 class="w3-text-teal">Safety: Neighbors do not eat at the same time</h3>
Let \(safe\) be the predicate <i>Neighboring clients are
not eating</i>, and let \(init\) be a predicate that holds initially.
<p>
The safety part of the specification is that \(safe\) holds in every state in every path from
every initial state:
<p>
\([init
\Rightarrow A(safe)]\)



<h3 class="w3-text-teal">Progress: Hungry agents eat eventually</h3>
The progress part of the specification is that every hungry agent
transits to eating state eventually.
<p>
For every agent \(v\):
<br>
\(
v.state = hungry \quad \leadsto \quad v.state = eating
\)

<h3 style="color:red;">Example of Safety</h3>
    <figure>
    <img src="Slide05.jpg" alt="Fig5" style="width:100%">
    <figcaption>Fig.5: Diagrams illustrating Safety</figcaption>
</figure>

Figure 5 shows a client eating as a red node depicting the client and
its OS agent. An uncolored node represents a client that is thinking
or hungry. The diagram on the left shows the system in a safe state:
there are no edges between red vertices. The diagram on the right
shows an unsafe state because there are edges between red vertices.


<h3 class="w3-text-teal">The Client's Program</h3>

<p>
We use two tokens that move
between a client and its OS agent. The tokens are called the
<i>resource token</i> and the <i>request token</i>. The client's
states are represented by which tokens the client holds.

<ol>
  <li><i>Thinking State</i>: A thinking client holds the request token but
  not the resource token.
  </li>
  <li><i>Transition: Thinking to Hungry</i>: Send the request token to
  the OS.
  </li>
  <li><i>Hungry State</i>: The client holds neither the request nor the
  resource token.
  </li>
  <li><i>Transition Hungry to Eating</i>: The client transits to
  eating when it receives both the request and resource token.
  </li>
  <li><i>Eating</i>: The client holds both the request and resource tokens.
  </li>
  </li>
  <li><i>Transition from Eating to Thinking</i>:
  The client holds sends the resource token to the OS and continues to
  hold the request token.
  </li>
</ol>

The figure below illustrates the states of the client. The request
    token is shown as a square and the resource token as a circle.
    <figure>
    <img src="Slide06.jpg" alt="Fig6" style="width:100%">
    <figcaption>Fig.6: Client's Program</figcaption>
</figure>

Initially all clients are thinking; all resource tokens are with OS
agents; and all request tokens are with clients.

<h3 class="w3-text-teal">What the OS Knows</h3>
While the OS agent holds the request token it knows that its client is
hungry. While the OS agent holds the resource token it knows that its client is
not eating.
    <figure>
    <img src="DiningPhilosophers/Slide23.jpg" alt="Fig6" style="width:100%">
    <figcaption>Fig.7: OS Agent's Program</figcaption>
</figure>


<p>
When a client transits from thinking to hungry it sends its request
token to the agent. When the OS receives the request token, the OS
also has the resource token; so the OS knows that its client is
hungry. There is an interval after the client sends the request token
and before the OS receives it during which the client is hungry but
the OS doesn't know that. An OS agent does not need to know 
what state its client is in at every point. Likewise, a client does
not need to know its OS agent's state at every point.
<p>
A client is hungry <i>leads-to</i> its OS agent knowing that its client is
hungry. The <i>leads-to</i> captures the fact that the OS doesn't know
the client's state at the instant that the client transitions from
thinking to hungry.
<!--------------------------------------------------------------->
<h2 class="w3-text-teal">Introduction of Tokens</h2>
We introduce a token on each edge of the agent communication graph,
see figure 4. The token on an edge \(v, w\) is in one of four states:
held by \(v\), in the channel from \(v\) to \(w\), held by \(w\), or
in the channel from \(w\) to \(v\). Therefore while \(v\) holds this
token it knows that \(w\) doesn't hold it. Likewise, while \(w\) holds
this token it knows that \(v\) doesn't.

    <figure>
    <img src="Slide07.jpg" alt="Fig7" style="width:100%">
    <figcaption>Fig.7: Fork on each edge of the agent communication
    graph</figcaption> 
</figure>

<p>
These tokens are called <i>forks</i>. (They are called
<i>chopsticks</i> in some papers.) An agent eats only if it holds
forks for all the edges incident on it. Therefore, while an agent eats
none of its neighbors do, and so the safety specification is satisfied.

<!--------------------------------------------------------------->
<h3 class="w3-text-teal">Key Question: When does a hungry agent yield
forks?</h3>
An eating philosopher holds on to all its forks until it finishes
eating. A thinking philosopher can give a fork to a neighbor that
requests it. So the key question is: <i>Under what conditions should a
hungry neighbor give a fork that it holds to a neighbor that requests
it?</i>

<p>
Suppose every hungry agent gives a fork to a neighbor that requests
it. Then we can get the scenario shown in the figure below.

    <figure>
    <img src="Slide08.jpg" alt="Fig8" style="width:100%">
    <figcaption>Fig.8: Scenario when hungry agents yield forks</figcaption> 
</figure>
The figure shows a system with 3 agents indexed 0, 1, 2. The forks are
    shown as small colored circles. The state on
    the left shows agent \(j\) holding the fork that it shares with
    agent \((j+1)\:\textrm{mod}\:3\). If each agent yields the fork to
    its neighbor we get the state on the right in which agent \(j\)
    holds the fork that it shares with 
    agent \((j-1)\:\textrm{mod}\:3\). So, if all hungry agents yield
    forks, the states can alternate for ever between the one on the
left and the one on the right. In this case hungry agents starve: they
    remain hungry forever.

<p>
If hungry agents don't yield forks then the state on the left persists
for ever. In this case too, hungry agents starve.


<!--------------------------------------------------------------->
<h3 class="w3-text-teal">Creating a Partial Order of Priorities</h3>
Let's assign priorities to agents so that a hungry agent \(v\)
releases a fork to a neighbor \(w\) only if \(v\) has lower priority
than \(w\). If there is a cycle of agents, all with the same priority,
then we get the situation shown in figure 8. So, we will ensure that
priorities form a partial order in all states in all
transitions. Priorities form a partial order exactly when the priority
graph is acyclic. The graph has an edge from \(v\) to \(w\) exactly
when \(v\) has higher priority over \(w\).

<p>
In the figure below, the diagram on the left shows an acyclic priority
graph while the one on the right shows a graph with a cycle.

    <figure>
    <img src="Slide09.jpg" alt="Fig9" style="width:100%">
    <figcaption>Fig.9: Priority Graph must be Acyclic</figcaption> 
</figure>




<!--------------------------------------------------------------->
<h3 class="w3-text-teal">How should Priorities Change?</h3>

<figure>
    <img src="Slide10.jpg" alt="Fig10" style="width:100%">
    <figcaption>Fig.10: How should priorities change when \(v\)
    eats?</figcaption>  
</figure>

How should priorities change when an agent eats so that the priority
graph remains acyclic? For example, consider
the priority graph shown in figure 10. Assume agent \(v\) has all its
forks and is about to eat. Should the directions of edges incident on
\(v\) be flipped? Or should \(v\) have lower priority than all its
neighbors, i.e. all edges incident on \(v\) point towards \(v\)?

<p>
What happens if we flip the directions of the edges incident on \(v\)?
After the flip, the edges are directed from \(w\), \(x\) and \(y\) towards \(v\), and
from \(v\) to \(u\). But now we have a cycle: \(y\) to \(v\) to \(u\)
to \(w\) to \(y\). So, flipping edge directions doesn't work.  

<p>
What happens if agents adopt the good neighbor policy?
The winner of a conflict gives itself lower priority than <i>all</i> the agents
with which it competes. So, an agent that starts eating gives itself lower
priority than all its neighbors. All edges point towards an eating
agent. 
<figure>
    <img src="Slide11.jpg" alt="Fig11" style="width:100%">
    <figcaption>Fig.11: Winner gets lower priority than its neighbors</figcaption> 
</figure>
When all edges incident on a vertex point towards the vertex then
there is no cycle through that vertex. So, directing all edges
incident on an eating vertex towards the eating vertex maintains
acyclicity of the graph.
<p>
For example, in the figure directing all edges incident on vertex \(v\) towards
 \(v\) ensures that no new cycle is created.

<h4 class="w3-text-teal">
Agent's priority does not decrease until the agent
eats.</h4>

<h3 class="w3-text-teal">How an Agent knows its Priority</h3>
We assign an attribute <i>clean / dirty</i> to forks.
A fork is either <i>dirty</i> or <i>clean</i>.
The forks held by an eating agent are <i>dirty</i>. When
an agent receives a fork from another agent, the receiving agent
cleans the fork. So the receiver holds a <i>clean</i> fork, and the
fork remains clean until an agent next eats with it.
(This is the "hygenic solution:" Another - sad? - attempt at CS
humor.)

<p>
An agent holding a dirty fork knows that it has lower priority than
the agent with which it shares the fork. Likewise,
an agent holding a clean fork knows that it has higher priority than
the agent with which it shares the fork.
<p>
If an agent does not hold the fork that it shares with a neighbor then
the agent does not know its priority with respect to that neighbor.

<h2 style="color:red;">Example of a Fork's Lifecycle</h2>
The diagram below shows states of a fork shared by agents \(u\) and
\(v\). The red arrow shows priority, and the black arrows show
channels. The blue dot represents the fork.

<p>
In the figure on the top left, agent \(u\) is hungry and holds a clean
fork. So, \(u\) knows that it has priority over \(v\). At this point
\(v\) does not know whether \(v\) has priority over \(u\) or not.
<p>
The next figure, at the top right, shows that when \(u\) transits from
hungry to eating, the fork becomes dirty, and \(u\) has lower priority
than \(v\). Agent \(u\) continues to hold the fork while it eats.
<p>
The next figure, bottom right, shows the situation after \(u\) gets a
request for the fork from \(v\). Because \(u\) got the request from
\(v\) and \(u\) hasn't sent the fork to \(v\), agent \(u\) knows that
\(v\) is hungry. Since the fork is dirty, \(u\) sends
the fork to \(v\). The figure shows the fork in the channel from \(u\)
to \(v\). While the fork is in the channel it doesn't matter
whether the fork is clean or dirty; however, merely for convenience,
let's assume that \(u\), being hygenic, cleans the fork before sending
it to its partner. While the fork is in a
channel the priority doesn't change but neither \(u\) nor \(v\) knows
what the priority is. 
<p>
The next figure, bottom left, shows the situation when \(v\) receives
the fork.  Receiving the fork doesn't change the priority.
At this point \(v\) is hungry and the fork is
clean and so \(v\) knows that it has higher
priority. \(v\) holds on to the fork until it next eats.

<figure>
    <img src="Slide12.jpg" alt="Fig12" style="width:100%">
    <figcaption>Fig.12: How an Agent knows its Priority</figcaption> 
</figure>

<h2 class="w3-text-teal">Algorithm</h2>
<h3 class="w3-text-teal">Properties of Reachable States</h3>
Here is a list of some of the properties of states in all
trajectories. 
<ol>
  <li>
  The priority graph is acyclic. \(u\) has priority over a neighbor
  \(v\) exactly when \(u\) holds the fork that it shares with \(v\)
  and the fork is clean, or the fork is in the channel from \(v\) to
  \(u\), or \(v\) holds the fork and the fork is dirty.
  </li>
  <li>
  Eating philosophers hold the forks for all edges incident on them,
  and these forks are dirty.
  </li>
  <li>
  All forks held by thinking philosphers are dirty.
  </li>
  <li>
  Thinking philosophers never send requests and never receive
  forks. Thinking philosophers respond to request for forks by sending
  the requested forks.
  </li>
</ol>

<h3 class="w3-text-teal">Initial States</h3>
Initially all philosophers are thinking; all forks are dirty; and all channels are
empty. The forks are placed so that the priority graph is acyclic.
The initial assignment of forks is as follows.
Given an arbitrary acyclic graph, for any edge directed from \(v\) to
\(w\), the fork shared by \(v\) and \(w\) is initially at \(w\) and
the fork is dirty. 

<h3 class="w3-text-teal">Algorithm Commands</h3>

<p>
The algorithm is specified by the following commands.
<ol>
  <li>
  When a thinking philosophers gets a request for a fork that it holds
  it sends the fork. (A fork held by a thinking philosopher is dirty.)
  </li>
  <li>
  When a thinking philosopher transits to hungry it sends requests for
  all forks that it does not hold.
  </li>
  <li>
  When a hungry philosopher receives a fork, it records the fork as
  being clean. If the hungry philosopher holds all its forks, and if
  it has no request for any dirty fork that it holds, then it transits
  to eating, and records all the forks that it holds in the eating
  state as dirty. 
  </li>
  <li>
  When a hungry philosopher receives a request for a fork that it
  holds, it sends the fork if the fork is dirty, and holds on to the
  fork if it is clean.
  </li>
  <li>
  When an eating philosopher receives a request for a fork it
  registers the request in memory, and continues eating while holding
  the fork. When an eating philosopher transits to thinking it sends
  forks for all requests that it received.
  </li>
</ol>


<h4 class="w3-text-teal">What could go wrong?</h4>
The proof of safety is straightforward: Neighbors aren't eating
because neighbors can't hold the same fork at the same time.

<p>
Before we look at the proof of progress, let's see what may go wrong.

<p>
Could a group of philosophers exchange forks with each other so that
members of the group eat repeatedly, and starve a philosopher who is
not in the group? For example, in the figure below, could philosophers
\(u, v, w\) exchange forks so that they each eat in turn, and starve
\(y\)? 
<figure>
    <img src="Slide13.jpg" alt="Fig13" style="width:100%">
    <figcaption>Fig.13: Potential Problems: What could go wrong?</figcaption> 
</figure>
<p>
Could the system enter a deadlock state in which each hungry philosopher in a
group holds only some --- but not all --- of the forks that it needs
to eat, while other members of the group hold the remaining forks?

<h2 class="w3-text-teal">Proof of Correctness</h2>
The algorithm is correct. We are required to prove that every hungery
philosopher eats eventually:
<p>
\(
\forall v: \quad v.h \leadsto v.e
\)
<p>
where for a philosopher \(v\), \(v.h\) holds exactly when \(v\) is
hungry and \(v.e\) holds exactly when \(v\) is
eating.

<h3 class="w3-text-teal">Variant Function</h3>
To prove this progress property we find a variant function that
satisfies the following two conditions:
<ol>
  <li>
  <i>Safety</i>: The variant function does not increase while \(v\)
  remains hungry. 
  </li>
  <li>
  <i>progress</i>: The following predicate does not hold forever: The
  variant function remains unchanged and \(v\) remains hungry.
  </li>
</ol>

<p>
We propose a variant function which is a pair of integers
 \(nT, nH\),  which are the number of thinking and hungry philosophers,
respectively, of 
higher priority than \(v\).
In terms of the priority graph, \(nT, nH\) are the numbers of thinking
and hungry philosophers (i.e. vertices) with paths to \(v\). 

<h3 style="color:red;">Example of Variant Function</h3>
The figure below shows a portion of the priority graph in a state of the
system. The figure only shows philosophers with higher priority than
philosopher \(v\), i.e., it only shows vertices in the graph with
paths to \(v\). Since eating philosophers have lower priority than
their neighbors, eating philosophers don't appear in this graph.
<p>
A hungry philosopher is marked with an "H" and a thinking philosopher
with a "T." In the diagram, philosophers \(v, w, x, y\) are hungry and
\(u\) is thinking.
Forks are located at philosophers and are shown as small
colored circles. A dirty fork is colored red and clean one is
blue. For example the fork shared by \(v\) and \(y\) is at \(y\) and
is clean.


<figure>
    <img src="Slide15.jpg" alt="Fig15" style="width:100%">
    <figcaption>Fig.15: A Variant Function: Numbers of higher priority
    thinking, hungry agents</figcaption> 
</figure>

<h3 style="color:red;">Example of Changes to Variant Function</h3>
The next figure is an example of changes to the variant function. The
diagram on the top left shows the higher priority vertices in the
state of the previous figure. If agent \(x\) eats next the priority
graph transits to the diagram on the top right, and the variant
function \((nT, nH)\) changes from \((1, 3)\) to \((1, 2)\). 



<figure>
    <img src="Slide16.jpg" alt="Fig16" style="width:100%">
    <figcaption>Fig.16: Example of Values of the Variant Function</figcaption> 
</figure>


If agent \(y\) eats next the priority
graph transits to the diagram on the bottom right, and the variant
function \((nT, nH)\) changes from \((1, 2)\) to \((1, 1)\).

If agent \(w\) eats next the priority
graph transits to the diagram on the bottom left, and the variant
function \((nT, nH)\) changes from \((1, 1)\) to \((0, 0)\).

<h4 class="w3-text-teal">Proof that the variant function does not increase
while \(v\) remains hungry</h4>


<p>
If a philosopher of higher priority than \(v\) transits from thinking
to hungry then \(nT\) decreases. Though \(nH\) increases, the variant function \((nT,
nH)\) decreases because ordering of function values is done
lexicographically.
<p>
If a philosopher of higher priority than \(v\) transits from hungry
to eating then \(nH\) decreases,  and so the variant function \((nT,
nH)\) decreases.

<h4 class="w3-text-teal">Proof that the following predicate does not
hold forever: The variant function remains unchanged and
\(v\) remains hungry.
</h4>

<p>
Let \(w\) be a highest-priority hungry philosopher, i.e. a philosopher with no
hungry philosopher with priority higher than \(w\). (Note: \(w\) may be
the same as \(v\).)
All philosophers with priority higher than \(w\) are thinking. In the
next paragraph we show that either \(w\) gets all its forks and then transits
from hungry to eating, or the variant function decreases.

<p>
From the algorithm, a hungry philosopher \(w\) requests forks from its
neighbors. From the algorithm, \(w\) eventually gets forks from 
all its lower priority neighbors. A higher priority neighbor \(x\) of
\(w\) is thinking. So when \(x\) gets a request for a fork from \(w\)
either (1) \(x\) sends the requested fork to \(w\) or (2) \(x\) transits from
thinking to hungry in which case the variant function \((nT, nH)\)
decreases. 

<h2 class="w3-text-teal">Summary: Key Ideas of this Module</h2>
This module introduced the problem of distributed mutual exclusion;
showed how the good neighbor policy --- a winning agent reduces its
priority to be lower than all the agents that it competes with --
solves this conflict resolution problem; introduced tokens and what
agents know about other agents holding tokens; and showed a proof
pattern that is one of the most common patterns for proving progress.

<h4 style="color:blue;">Review</h4>
<ol>
  <li>
  What is the meaning of mutual exclusion among neighboring
  philosophers?
  </li>
  <li>
  An invariant of the algorithm is that each token is in exactly one
  place: an agent or a channel. How does this invariant help in
  designing the algorithm?
  </li>
  <li>
  An invariant of the algorithm is that the relative priorities among
  agents forms a partial order --- the priority graph is acyclic. What
  can go wrong if the priority graph has cycles?
  </li>
  <li>
  An agent that has a request for a fork releases the fork if the fork
  is dirty, and holds on to the fork if the fork is clean. What could
  go wrong if an agent releases a fork when it gets a request,
  regardless of whether the fork is clean or dirty?
  </li>
</ol>
