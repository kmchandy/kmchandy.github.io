<title>Paxos/Paxos.html</title>

<!------------- Start Heading -------------------------------->
<!DOCTYPE html>

<html lang="en">
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1">

<link rel="stylesheet"
href="https://www.w3schools.com/w3css/4/w3.css">

<link rel="stylesheet"
href="https://fonts.googleapis.com/css?family=Roboto">

<link rel="stylesheet"
href="https://www.w3schools.com/lib/w3-theme-blue.css">

<link rel="stylesheet"
href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">

<style>
html,body,h1,h2,h3,h4,h5,h6 {font-family: "Roboto", sans-serif;}
.w3-sidebar {
  z-index: 3;
  width: 250px;
  top: 43px;
  bottom: 0;
  height: inherit;
}
/* Thick blue border */
hr.new2 {
  border: 2px solid blue;
}
/* blue border */
hr.new1 {
  border: 2px solid blue;
}
</style>


<body>


<div class="w3-top">
<div class="w3-bar w3-theme w3-top w3-left-align w3-large">
  
  <a class="w3-bar-item w3-button w3-right w3-hide-large
  w3-hover-white w3-large w3-theme-l1"
  href="javascript:void(0)"
  onclick="w3_open()">
  <i class="fa fa-bars"></i></a>

  <a href="../index.html"
  class="w3-bar-item w3-button w3-hide-small w3-hover-white">
  Distributed Algorithms
  </a>

  <a href="../table_of_contents.html"
  class="w3-bar-item w3-button w3-hide-small w3-hover-white">
  Contents
  </a>

  <a href="../cross_reference.html"
  class="w3-bar-item w3-button w3-hide-small w3-hover-white">
  Index
  </a>
    
  </div>
  </div>
  
  <script id="MathJax-script" async
      src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js">
</script>
  
<div class="w3-row w3-padding-64">
<div class="w3-twothird w3-container">


    <!--------------------------------------------------------->
  <h1 class="w3-text-teal">The Paxos Algorithm</h1>

  
  <!-------------------------------------------------->
  <p class="w3-text-red">

  This page describes
  <a
    href="https://en.wikipedia.org/wiki/Paxos_(computer_science)">
  <i>Paxos</i>
  </a>,
  an algorithm by which agents come to a consensus about a value from
  a set of proposed values. 

  Paxos enables consensus to be reached in most situations, though
  there is a possibility that the algorithm may not terminate.

  </p>
  <p>
 
  
  From
  <a href="../ConsensusImpossible/ConsensusImpossible.html">the
  FLP theorem</a>,
  
  there is no algorithm that guarantees that consensus among agents
  will be reached if messages can be lost and delayed, and if agents may
  fail and be arbitrarily slow. 

  Paxos may not terminate though it enables consensus to be reached in
  most situations.

  <p>
  Paxos deals with systems in which messages may be lost; multiple
  copies of a message may be delivered; messages may not be
  delivered in the order sent; agents may be arbitrarily slow; and
  agents may stop.


    
  <!-------------------------------------------------->
  <h4 class="w3-text-teal">Implementing a Synchronous Algorithm on a
  Lossy Distributed System
  </h4>
  <!-------------------------------------------------->
We begin by describing a method for implementing a synchronous
  algorithm on a distributed system with lossy channels.

  A set \(P\) of agents reads and writes a  shared
  object \(v\).

  An agent \(p\) in \(P\) has local variables \(p.r\) and \(p.w\)
  which are the most recent value of \(v\) that
  \(p\) has read, and the most recent value that \(p\) has written,
  respectively. 

  <p>
 The following iterations ensure that at most one agent
  accesses the shared object at a time.
  <ol>
    <li>
    Select any one agent \(p\) in \(P\). The selection is
    nondeterministic.
    </li>
    <li>
    Copy \(v\) into \(p.r\).
    </li>
    <li>
    Compute \(p.w\) as function of \(p.r\) and other local variables
  of \(p\).
    </li>
    <li>
    Copy \(p.w\) into \(v\).
    </li>
  </ol>

  <p>
  The shared object is implemented by having an
  agent \(a\) with a local variable \(a.v\), where \(a.v\) is the
  shared object.
  
  An agent \(p\) reads \(v\) into \(p.r\) by sending a read request to
  \(a\) which replies with \(a.v\).

  When \(p\) receives the reply \(p\) copies \(a.v\) into \(p.r\).

  <p>
  Agent \(p\) writes \(p.w\) by sending a write
  request containing \(p.w\) and when \(a\) gets the request it
  sets \(a.v\) to \(p.w\).

  <p>
  Next, we show how timestamps are used to select a single agent \(p\)
  from a set.
  Each message \(m\) sent between a proposer \(p\) and \(a\) has a
  timestamp \(m.t\).
  Each proposer \(p\) has a local variable \(p.t\) and \(a\) has a
  local variable \(a.t\).
  The central feature of the algorithm is this: \(a\) ignores any
  message \(m\) that it receives if \(m.t < a.t\).


A proposer \(p\) sends ReadRequest and WriteRequest messages to \(a\).
\(a\) replies to a ReadRequest with a ReadReply message.
In addition, each proposer sends a Timeout message to itself.

<p>
Each proposer starts by sending a Timeout to itself.
If a proposer receives a Timeout message it increments its own time by
a positive amoung \(h()\) and sends a read request to \(a\).
The timestamp of the read request is the proposer's time (written here
as <code>self.t</code>).
The proposer then sleeps for an aribtrary (finite) amount of time, and
then sends itself a Timeout message.

<p>

The pseudo-code for an agent \(p\) is given below in Python-like notation.

  
<pre>
send(Timeout, self)
start()

def receive(m, sender):
   if isinstance(m, Timeout):
        self.t = self.t + h()
        send(ReadRequest(t=self.t), a)
        time.sleep(..)
        send(Timeout, self)
   elif m.t == self.t:
         send(WriteRequest(v=f(..), t=self.t), a)
  </pre>

If \(p\) receives a message \(m\) of type <i>ReadReply</i> and \(m.t =
  p.t\) then \(p\) sends a write request to \(a\) requesting \(a\) to
  write the value returned by a function \(f(..)\) into \(a.v\).
  The time field of the write request is \(p.t\).

  


  
  
<pre>
def receive(message, sender):
   if instance(message, Reply):
      if message.time == my_time:
         received_reply[sender] = message.value
         if len(received_reply) > num_acceptors/2:
            send_message = WriteRequest(
                value = f(received_reply, ...),
                time  = my_time
            for all acceptor in acceptors:
               send(send_message, acceptor)
   else:
        // message is Timeout
        sleep_time = g()
        time.sleep(sleep_time)
        my_time = my_time + h()
        received_reply = {}
        msg = ReadRequest(time = my_time)
        for acceptor in acceptors:
           send(msg, acceptor)
        send(Timeout, self)
</pre>
         
      
  

  
  
  <!-------------------------------------------------->
  <h4 class="w3-text-teal">A Sequential Model of Distributed Systems
  with Lossy Channels</h4>
  <!-------------------------------------------------->
  In a distributed system an agent \(p\) simulates reading local
  variables of a set of agents \(A\) as follows: \(p\) sends a message
  to each agent \(a\) in \(A\) requesting \(a\) to reply with
  values of \(a\)'s local variables.

  <p>
  Requests and replies may get lost in a system with lossy channels.
  
  So \(p\) gets replies from a subset of the agents in
  \(A\).

  We call this subset the <i>read subset</i>.

  The read subset is arbitrary -- it may be the empty set, or the
  entire set, or a nonempty proper subset.
  
  <p>
  Likewise, if \(p\) sends messages to all agents in \(A\),
requesting agents in \(A\) to update their local variables, some
  agents may not receive the messages.
So, agents in a subset of \(A\) update their variables.

We call this subset the <i>write subset</i>.


<!----------------------------------------------------------->
<h5 class="w3-text-teal">Majorities Accept Proposed Values</h5>
<!----------------------------------------------------------->

Next, we give an example of a while loop of a
sequential program which illustrates read and write subsets.

We later show how the while loop is converted to a distributed
algorithm for a system with lossy channels.

<p>
The variables of the loop are sets <code>P</code> and <code>A</code>
called the sets of proposers and acceptors, respectively.

A proposer <code>p</code> has a field <code>p.v</code> called
<code>p</code>'s value. 

An acceptor <code>a</code> has fields <code>a.v, a.t</code> called
<code>a</code>'s value and time, respectively.

An acceptor's value is the same type as a proposer's value, and an
acceptor's time is an integer.


<p>
Initially <code>a.v, a.t = None, 0</code> for all  <code>a</code>.
The symbol <code>None</code> indicates unassigned.
The steps of the loop are as follows.
<ol>
  <li>
  Select any <code>p</code> from the set <code>P</code>
  nondeterministically.
  </li>
  <li>
  Select a subset <code>read_subset</code> of <code>A</code>
  nondeterministically.
  </li>
  <li>
  If <code>read_subset</code> is a majority of acceptors then
  select a subset, <code>write_subset</code>, of <code>A</code>
  nondeterministically, and assign values to all elements in <code>write_subset</code>.
  </li>
</ol>

<pre>
  t = 0
  for a in A:
    a.v, a.t = None, 0
      
  while True:
    p = any_element(P)
    read_subset = any_subset(A)

    if len(read_subset) >= len(A)/2:
        write_subset = any_subset(A)
        for a in write_subset:
           a.v, a.t = f(p, read_subset), t
    t = t + 1
</pre>

Next we describe function <code>f</code>.

If the time for all acceptors in <code>read_subset</code> is 0 then
the function returns <code>p.v</code>, the proposer's value.

Otherwise the function returns the value of the acceptor in
<code>read_subset</code> with the largest time.

<pre>
def f(p, read_subset):
   v, t = p.v, 0
   for a in read_subset:
      if a.t > t:   v, t = a.v, a.t
   return v
</pre>


<h5 class="w3-text-teal">Properties of the Sequential Program</h5>
The proof of the following observation is straightforward.

<p>
In all states of the computation, for all acceptors \(a\),
<ol>
  <li>
  <code>a.t</code> is the iteration number in which <code>a.v</code>
  was last assigned a value.
  </li>
  <li>
  \(a\)'s value is None or is a value of some proposer.
  <p>
  \(
  \forall a:  (a.v = None) \vee (\exists p: a.v = p.v)
  \)
  </li>
</ol>

  The program has the following property.
  If in the \(n\)-th iteration, for any \(n\) the write subset is a majority and acceptors in
  the write subset are assigned a value \(u\)
  then, in subsequent iterations an acceptor's value
  does not change or changes to \(u\).
  <p>


<p>
The property can be written as follows. For all values \(u\),
iteration number \(n\) and majority \(M\) of acceptors:
<p>
\(
(\forall a \in M: a.v, a.t = u, n)
\)
<br>
\(
\Rightarrow
\)
<br>
\(
\forall a: (a.t < n) \vee (a.v = u)
\)
  


<!----------------------------------------------------------->
<h5 class="w3-text-teal">Proof of the property</h5>
<!----------------------------------------------------------->
Let \(M\) be a majority of acceptors, \(u\) be a value, and \(n\) be
an iteration number where all acceptors in \(M\) have value \(u\) and
time \(n\).

We will prove that in all states an acceptor's time is less than \(n\)
or its value is \(u\).

<p>
The result holds after the first \(n-1\) iterations because \(a.t <
n\) in these iterations.

The result holds after the \(n\)-th iteration, because if an
acceptor \(a\)'s variables are modified in this iteration then
\(a.v, a.t = u, n\).

<p>
Assume that the result holds after the first \(i \geq n\) iterations and
prove that it holds for the \(i+1\)-th.

We need only consider the case where the read subset in the iteration
is a majority, and 
in this case the read subset has an element in common
with majority \(M\).

So there is an element \(a\) of read subset in which \(a.t = n\) and
\(a.v = n\).
<p>






<h1>OLD</h1>
<h1>OLD</h1>
<h1>OLD</h1>
<p>
Next, we give an example of a synchronous algorithm for a message-passing system with
lossy channels and then map the algorithm to a single while loop of a
sequential program.

Later we show how the synchronous algorithm can be implemented in (asynchronous)
distributed systems.

<p>
  The system has nonempty sets <code>P</code> and <code>A</code> of
  agents called the sets of <i>proposers</i> and <i>acceptors</i>, respectively.
  Each proposer <code>p</code> has a local variable <code>p.v</code>, and each
  acceptor <code>a</code> has local variables <code>a.v</code> and
  <code>a.t</code>.

<p>
<code>p.v</code> is constant for all proposers <code>p</code>.
  Initially, <code>a.v = None</code> and <code>a.t = 0</code> for all
acceptors <code>a</code>.
  The symbol <code>None</code> indicates unassigned.


<p>
The program consists of a sequence of rounds where each round
  consists of the following synchronous phases. 

  <ol>
    <li>
    <i>The selection phase: </i>A single proposer <code>p</code> is
    selected nondeterministically. 
    </li>
    <li>
    <i>The read phase: </i>
    <code>p</code> sends read requests to all acceptors asking the
    acceptors to reply with the values of their local variables.
    An acceptor <code>a</code> which receives the request replies with
    a message <code>r</code> (for <i>r</i>ead) which has fields <code>id, v,
    t</code>, and where
<pre>
  r.id, r.v, r.t = a.id, a,v, a.t
</pre>
    
    Let <code>read subset</code> be the subset of acceptors from which
    <code>p</code> gets replies.
    </li>
    <li>
    <i>The write phase: </i>
    If the read subset is a majority of acceptors then <code>p</code>
    sends write requests to all acceptors.
    Let <code>write subset</code> be the subset of acceptors that update
    their values.
  </ol>
  

<p>
In the program, <code>P</code> is a set of arbitrary values, and
<code>A</code> is a set of objects where each <code>a</code> in
<code>A</code> has fields <code>a.v</code> and <code>a.t</code>.
Later, we use <code>A</code> to represent agents.

<p>
The algorithm proceeds in two phases.
First, send requ



  <!-------------------------------------------------->
  <h3 class="w3-text-teal">A Rounds-Based Algorithm</h3>

  A system has nonempty sets <code>P</code> and <code>A</code> of
  agents called the sets of <i>proposers</i> and <i>acceptors</i>, respectively.
  Each proposer <code>p</code> has a local variable <code>p.v</code>, and each
  acceptor <code>a</code> has local variables <code>a.v</code> and
  <code>a.t</code>.
  We call <code>p.v</code> the value proposed by <code>p.v</code>.

  <p>
  Initially, <code>a.v = None</code> and <code>a.t = 0</code>
  where the symbol <code>None</code> indicates unassigned.

  If an acceptor's value is any non-<code>None</code> <code>w</code>
  then we say that the acceptor has accepted <code>w</code>.
  We refer to <code>a.t</code> as <code>a</code>'s time.
  <p>
  Proposers send messages to, and receive messages from, acceptors.
  Messages may get lost or delayed by arbitrary amounts.

  The problem is to design an algorithm with the following
  specification:
  <ol>
    <li>
    Acceptors only accept proposer's values.
    <p>
    \(
    \forall a: (a.v = None) \vee (\exists p: a.v = p.v)
    \)
    </li>
    <li>
    If a majority of acceptors accept the same value, <code>v*</code>
  and have the same time <code>t*</code> at any point in a
    computation, then in all points of the computation an acceptor has also accepted
  <code>v*</code> or its time is less than <code>t*</code>.

    <p>
    \(
    (\exists v*, t*, M: \forall a \in M: a.v, a.t = v*, t*)
    \)
    <br>
    \(
    \Rightarrow
    \)
    <br>
    \(
    (\forall a: (a.v = v*) \vee (a.t < t*))
    \)
    </li>
 </ol>
  



  in a sequence of rounds where each round
  consists of the following synchronous phases. 

  <ol>
    <li>
    A single proposer is selected nondeterministically.
    Let's call this proposer the <code>p</code>.
    </li>
    <li>
    <i>The read phase: </i>
    <code>p</code> sends read requests to all acceptors asking the
    acceptors to reply with the values of their local variables.
    <code>p</code> receives replies from none, some, or all acceptors
    because messages may be lost.
    Let <code>read subset</code> be the subset of acceptors from which
    <code>p</code> gets replies.
    </li>
    <li>
    <i>The write phase: </i>
    If the read subset is a majority of acceptors then <code>p</code>
    sends write requests to all acceptors.
    When an acceptor receives a write request it 
    updates its local variables with the values specified in
    the request.
    
    A subset of acceptors update their values because some write requests may be lost.
    Let <code>write subset</code> be the subset of acceptors that update
    their values.
  </ol>
  
  
  The sequence of rounds can be represented by a loop in a sequential program.

  <pre>
  t = 0
  for a in A:
    a.v = None
    a.t = 0
      
  while True:
    p = any_element(P)
    read_subset = any_subset(A)

    if len(read_subset) >= len(A)/2:
        write_subset = any_subset(A)
        for a in write_subset:
           a.v = f(v, read_subset)
           a.t = t
    t = t + 1
   </pre>

  <!-------------------------------------------------->

  
  The problem is to design phase 3 so that if on any given round \(T\), the selected
    proposer sends write requests, and the write
    subset is large enough, and for all acceptors <code>a</code> in the
    write subset, <code>a.v = V*</code>, 
In the code outline, <code>h</code> is a boolean function of the
  variables in read subset.
  The call <code>update(a, read_subset, t)</code> modifies
  <code>a</code> with values that depend on <code>read_subset</code>
  and <code>t</code>.
  
    

    (1) read any
  subset \(r\) of acceptors, and (2) write any subset \(w\) of acceptors.
  
  Proposers propose values and acceptors may accept or ignore the
  proposed values.

  <p>
  On each round, exactly one proposer \(p\) is selected, and \(p\)
  sends messages to, and receives messages from, acceptors in this
  round.

  The only communication in a round is between the selected
  proposer and acceptors.

  Messages may get lost.

  Messages sent in a round are received in the round.

  <p>
  We want to design an algorithm with the following specification.

If a majority of acceptors accept the same value on any round then in
    all subsequent rounds all m

  <h1>OLD</h1>

  
    

  
  Let's begin with a sequential program with a single loop.

  Later, we will map the sequential algorithm to a distributed
  system. 

  <p>
  The variables of the algorithm are nonempty sets \(A\) and \(P\) of
  objects called <i>acceptors</i> and <i>proposers</i>, respectively.
  Associated with each proposer <i>p</i>, and each acceptor <i>a</i>
  are values <p.v> and <a.v>, respectively.
  Each acceptor has an additional field, <i>a.t</i>.

  Let <i>M</i> be the number of elements that constitute a majority of
  acceptors. 

  <p>
  The \(t\)=th iteration of the loop consists of four steps:
  <ol>
    <li>
    Select any proposer <i>selected_proposer</i>
    </li>
    <li>
    Select any subset <i>read_subset</i> of acceptors.
    </li>
    <li>
    Select any subset <i>write_subset</i> of acceptors.
    </li>
    <li>
    If <i>read_subset</i> is a majority of acceptors, then
    for each <i>a</i> in <i>write_subset</i>. 
    assign
    <i>f(selected_proposer, read_subset)</i> to <i>a.v</i> and assign <i>t</i> to
    a.t</i>. We specify <i>f</i> later.
    </li>
</ol>
The selections in the algorithm are nondeterministic.
A selected subset of acceptors may be the empty subset.

  <h3 class="w3-text-teal">Specification</h3>

  The algorithm assumes that messages are not modified in transit and agents
  do not exhibit Byzantine behavior -- agents may be arbitrarily slow,
  they may stop and restart, but they otherwise obey the protocol.

  <p> A system has agents called <i>proposers</i> and agents called
  <i>learners</i>.

  Proposers propose values and learners come to a consensus among the
  proposed values. 

    <p>
Each learner \(L\) has a local variable \(L.v\) 
  which is initially \(null\).
  If \(L.v\) becomes any non-null value \(w\) then we
  say that \(L\) has learned \(w\).

  Associated with each proposer \(P\) is a
local constant \(P.V\) which is its proposed value. The specification
 of the algorithm is that the 
 following conditions must always hold.
<p>
<ol>
  <li>
  Learners learn only proposed values.
  <br>
  \(\forall \; \textrm{learners} \;  L: \quad
  (L.v = null) \; \vee \;
  (\exists \; \textrm{proposer} \: P : L.v = P.V)
  \)
  </li>
  <li>
  A learner doesn't change a value that it learns.
  <br>
  \(
  \forall \; \textrm{learners} \; L, V \neq null: \quad stable (L.v = V)
  \)
  </li>
  <li>
  All learners learn the same value.
  <br>
  \(
  \forall \; \textrm{learners} \; L, L': \quad
  (L.v = null) \vee (L'.v = null) \vee 
  ( L.v = L'.v)
  \)
  </li>
</ol>
The specification allows for the possibility that
consensus may never be reached; a learner may never learn a value. 


<!------------------------------------->
<h4 class="w3-text-teal">Introduction of Acceptors and Timestamps</h4>

The algorithm uses agents called <i>acceptors</i> in addition to
proposers and learners. 

Each acceptor <i>A</i> has two local variables, <i>A.v</i> and
<i>A.t</i>, where <i>A.v</i> is either a special symbol null or a
proposer's value, and <i>A.t</i> is a number which is initially
\(0\).
\(A.v\) and \(A.t\) are
called \(A\)'s <i>value</i> and <i>timestamp</i>, respectively.

<p>
We will see that an agent's timestamp does not decrease, and that
timestamps specify
<a href = "../ChannelSnapshots/TimeProperties.html">
rounds in a timeline.</a>
We shall say that acceptor \(A\) has accepted \(A.v, A.t\) if \(A.v\) is not null.


<h3 class="w3-text-teal">Basic Consensus</h3>
  Before describing Paxos, we specify a subproblem, called
  <i>basic consensus</i> that is solved in Paxos. Basic consensus is
specified in terms of proposers and acceptors without learners.

<h5 class="w3-text-teal">Specification of Basic Consensus</h5>
<ol>
  <li>
Acceptors accept only proposer's values.
<p>
\(
(\exists \; \textrm{proposer} \; P: A.v = P.v) \vee (A.v = null)
\)
</li>
<li>
If there exists there exists \(vM, tM\), and a point in the
computation where all acceptors in a majority \(S\) accept \(vM, tM\)
<p>
\(
(\forall C \in S: C.v, C.t = vM, tM) \wedge (vM \neq null)
\)
<p>
then at all points in the computation, every acceptor with timestamp
\(tM\) or greater has value \(vM\)
<p>
\(
\forall \; \textrm{acceptors} \; A \; \textrm{where} \; A.t \geq tM: \;
  A.v = vM
\)

</li>
</ol>

<p>
Before giving a distributed algorithm for basic consensus we analyze a
for-loop in a sequential algorithm. The sequential algorithm gives
insight into the distributed version.

<!------------------------------------->
<h4 class="w3-text-teal">A Sequential Simulation of the Basic
Consensus Algorithm</h4>

The sequential program consists of a for-loop with loop index \(k\).
Initially, \(A.v, A.t = null, 0\) for all acceptors \(A\).

<p>
The loop body selects an arbitrary proposer <code>P</code>, and
arbitrary subsets <code>R, W</code> of acceptors; these selections simulate
nondeterminism and faults in the distributed system.

In the loop, agents are treated as shared variables.
For example, the loop reads and writes <code>A.v, A.t</code> for an
acceptor <code>A</code>.


<h5 class="w3-text-teal">Loop Body of the Basic Consensus
Algorithm</h5>

The loop body for the \(k\)-th iteration is as follows.

<ol>
  <li>
  Select an arbitrary proposer <code>P</code>, and arbitrary subsets
  <code>R,W</code> of acceptors.
  </li>
  <li>
  If <code>R</code> is not a majority then take no action.
  </li>
  <li>
  If <code>R</code> is a majority then for all acceptors \(A\) in
  <code>W:  A.v, A.t = f(R), k</code>
  </li>
</ol>

<h5 class="w3-text-teal">Function f</h5>
<ol>
  <li>
If <code>A.v = null</code> for all <code>A</code> in <code>R</code>
  then <code>f(R) = P.v</code>;
  </li>
  <li>
  else <code>f(R) = C.v</code>
  <br>
  where <code>C</code> is a member of
  <code>R</code> with the largest  timestamp, i.e.,
  <br>
  <code>
  C.t = max({r.t | r in R})
  </code>
  </li>
</ol>


<!-------------------------------------------->
<h3 style="color:red;">Example of Sequential Simulation of Basic Consensus</h3>
This example has acceptors A0, A1, A2 and two proposers with values X
and Y. Each row of the table shows the values of variables on the
\(k\)-th iteration where \(k = 0\) represents initial conditions. The
symbol <i>-</i> is used instead of \(null\).

<pre>
k   P.v   R      W      A0         A1         A2
0   -     -      -      (-, 0)     (-, 0)     (-, 0)
1   X     0      0,1    (-, 0)     (-, 0)     (-, 0)
2   X     0,1    1      (-, 0)     (X, 2)     (-, 0)
3   Y     0,2    0      (Y, 3)     (X, 2)     (-, 0)
4   Y     1,2    2      (Y, 3)     (X, 2)     (X, 4)
5   X     0,1    0,2    (Y, 5)     (X, 2)     (Y, 5)
6   X     1,2    1      (Y, 5)     (Y, 6)     (Y, 5)
7   X     0,1    2      (Y, 5)     (Y, 6)     (Y, 7)
8   X     1      1,2    (Y, 5)     (Y, 8)     (Y, 8)
</pre>

The columns with headings \(P.v, R, W\) specify the proposer, and
subsets of acceptors that are read, \(R\), and written, \(W\). For
example, on iteration 1, \(P.v = X\), \(R = \{0\}\), \(W = \{0,1\}\). The
values of the acceptors at the end of iteration \(i\) are shown in the row
where \(k = i\).

<h5 style="color:red;">Points to Note in the Example</h5>
The majority of \(A.v\) for acceptors \(A\) after iteration 4 is \(X\)
because \(A1, A2 = (X, 2), (X, 4)\). The final majority, however, is
\(Y\); see row 6.

<p>
In row 4, \(A1.t \neq A2.t\), and that's why the majority value does
not remain \(X\).
In row 5, the majority of acceptors have identical \(A.v\)
<i>and</i> \(A.t\), and so, from row 5 onwards, the acceptor with the
largest timestamp has value \(Y\).


<!-------------------------------->
<h3 class="w3-text-teal">Sequential
Simulator satisfies Specification of Basic Consensus</h3>

The proof of the invariance of part 1 -- acceptors accept only
proposer's values -- is
straightforward. Next, we prove part 2.

<p>
Consider the case where at the end of the \(k\)-th iteration
there exists \(vM \neq null\) such
that for all \(C\) in a majority \(S\) of acceptors:
<p>
\(
C.v, C.t = vM, k
\)
<p>
Then at the end of the \(k\)-th iteration conditions 1 and 2 hold:
<p><i>Condition 1</i>:
Acceptors have value
\(vM\) or earlier timestamps:
<p>
for all acceptors \(A\):
\(
  ( A.v = vM) \vee (A.t < k)
\)
<p><i>Condition 2</i>:
Values of all acceptors in \(S\) are \(vM\), and their timestamps are
at least \(k\).
<p>
for all acceptors \(C\) in \(S\):
\(
  (C.v = vM) \wedge (C.t \geq k)
\).

<p>
We will show that if conditions 1 and 2 hold at the beginning of the \(i\)-th
iteration, for \(i > k\), then they hold at the end of that iteration,
and therefore continue to hold thereafter. We will prove that if both
conditions hold and \(R\)
is a majority then \(f(R) = vM\) and so both conditions continue to hold.

<p>
Two majorities \(R\) and \(S\) have an element in common. Let
\(X\) be common to \(R\) and \(S\).

From condition 2,  \(X.t \geq k\).

Therefore, the element in \(R\) with the largest timestamp
  has a timestamp of \(k\) or greater.

<p>
From condition 1, if \(A.t \geq k\) then \(A.v = vM\).

So, the element in \(R\) with the largest timestamp has value
\(vM\), and therefore \(f(R) = vM\).
  




<!------------------------------------->

<h3 class="w3-text-teal">
A Round of a Distributed Basic Consensus Algorithm
</h3>

Next, we describe a computation of a Paxos algorithm where the computation
is a sequence of rounds, and each round is a distributed version of
the sequential simulation given earlier. The computation has
timelines for each of the proposers and acceptors. The reason for the
names of messages -- <code>prepare</code>, <code>promise</code>,
<code>accept</code> -- will become clear later.

<h4 class="w3-text-teal">Round \(k\) of the Computation</h4>

<p>
A round starts with the selection of a single proposer \(P\).
Later, we describe how the proposer is selected.
Round \(k\) has four steps which are as follows.

<ol>
  <li>
  \(P\) sends a message <code>prepare(k)</code> to all acceptors.
  <p>
  </li>
  <li>
  Each acceptor \(A\) that receives a <code>prepare(k)</code>
  message from \(P\) sends a reply <code>promise(k, A.v, A.t)</code>
  to \(P\).
  <p>
  </li>
  <li>
  If \(P\) receives <code>promise(k, _, _)</code> messages from a
  majority \(R\) of acceptors then \(P\) sends <code>accept(k,
  f(R))</code> messages to all acceptors. The symbol <code>-</code>
  represents an arbitrary value.
  <p>
  </li>
  <li>
  If an acceptor \(A\) receives an <code>accept(k, v)</code>
  message  then <code>A.v, A.t = v, k</code>.
  <p> 
  </li>
</ol>

<h5 class="w3-text-teal">Four Steps of Round \(k\) in Pseudo Code</h5>

<pre>
// Proposer P. Step P.1.
send prepare(k) to all acceptors

// Acceptor A. Step A.1: 
upon arrival of prepare() from a proposer P:
   send promise(k, A.v, A.t) to P

// Proposer P. Step P.2.
wait until
   end of round or
   arrival of promise(k, -, -) messages from any majority
   R of acceptors;

if promise messages are received from a majority R:
   send accept(k, f(R)) to all acceptors

// Acceptor A. Step A.2. 
upon arrival of accept(k, v): A.v, A.t = v, k
</pre>


<!------------------------------------->
<h4 class="w3-text-teal">Rounds in the Sequential Simulation and
Distributed Computation are Equivalent</h4>

Next we show that each round of the simulation is equivalent to each
round in the timeline.

Therefore a property that holds after a
round in the simulation also holds in the corresponding round of the
timeline.

So, the round-based timeline satisfies the specification of basic consensus.

<p>
In the distributed algorithm messages may get lost.
So proposer \(P\) receives
<code>promise</code> from an arbitrary subset \(R\) of acceptors.
Likewise, an arbitrary
subset \(W\) of acceptors receive <code>accept</code> messages.

<p>
  eading <code>A.v, A.t</code> from acceptors \(A\) in \(R\)
  in the sequential simulation is equivalent to receiving 
<code>promise(k, A.v, A.t)</code> from acceptors \(A\) in \(R\) in the
  distributed algorithm.


  Similarly, assigning <code>v, k</code> to each acceptor \(A\) in
  \(W\) in the sequential simulation
  is equivalent to each acceptor \(A\) in \(W\) receiving <code>accept(k,
v)</code> in the distributed algorithm.




<h3 class="w3-text-teal">The Distributed Basic Consensus Algorithm</h3>
Next we described a distributed basic consensus algorithm.
The algorithm obeys the rules for assigning
<a href="../ChannelSnapshots/TimeProperties.html"></a>
rounds to events.
Therefore, the causality graph of a computation of the distributed
algorithm is the same
as the causality graph of a computation that occurs as a sequence of
rounds.

A proof about states of agents in any computation
is also a proof for all computations with the same causality graph.
See the
<a href="../ChannelSnapshots/TimeProperties.html">section:
<i>A Technique for Analyzing Algorithms in Systems
with Message Loss</i>.
</a>


<!---------------------------------------->
<p>
A proposer \(P\) has a unique id \(P.id\) and a local integer variable
\(n\). The pair \([P.n, P.id]\) is a proxy for the iteration index
\(k\) of the sequential simulator, and the round id of the distributed
algorithm executing in rounds.

<p>
The timestamp for a message is its first field.

In the algorithm given below this field has value \(k\).

The time of an acceptor \(A\) is \(A.t\), and the time of proposer
\(P\) is \(P.t\).


<h5 class="w3-text-teal">The Basic Consensus Algorithm</h5>
<pre>
// Proposer P. Step P.1. 
P.n = P.n + any positive value
P.t = [P.n, P.id]
// P.t represents k in rounds of the timeline
send prepare(P.t) to all acceptors

// Acceptor A. Step A.1: 
upon arrival of prepare(k) at A from a proposer P:
   if k > A.t:
      A.t = k
      send promise(k, A.v, A.t) to P

// Proposer P. Step P.2.
wait until timeout or:
     arrival of promise(k, -, -) from any majority
     R of acceptors where k = P.t

If timeout: return to step P.1
else: send accept(k, f(R)) to all acceptors
      
// Acceptor A. Step A.2. 
upon arrival of accept(k, v):
    if k > A.t: A.t, A.v = k, v
</pre>


<h3 class="w3-text-teal">The Existence of a Computation Executing in Rounds</h3>
We will prove that given any computation \(C\) of the Paxos algorithm
there exists a timeline, with the causality
graph of timelines the Paxos algorithm, in which events occur in rounds:
All events at agents when the agents' time equal \(k\) occur before
all events at agents when the agents' time exceeds \(k\).


<h3 class="w3-text-teal">Theorem</h3>
Given any computation \(C\) of an algorithm in which messages may be lost,
where the algorithm follows the rules for assigning rounds, there
exists a computation \(C'\):
<ol>
  <li>
  with the same causality graph as \(C\) and
  </li>
  <li>
  in which, for all \(k\), events with round id \(k\) occur before
  events with round 
  ids that exceed \(k\), and 
  </li>
  <li>
  messages sent in a round are received in the same round.
  </li>
</ol>

The proof follows from the rules for assigning round ids to events and
messages.

<ol>
  <li>
  A message sent in an event with round id \(k\) has
  timestamp \(k\).
  </li>
  <li>
  A message with round id \(k\) is discarded if the message arrives
  at the receiver when the receiver's round id exceeds \(k\).
  </li>
  <li>
  When a message with timestamp \(k\) arrives at an agent with
  timestamp \(k\) or greater the message is either discarded or the
  receiver's timestamp is set to \(k\).
  </li>
</ol>
  


<figure>
    <img src="PaxosFigures/PaxosFigures.012.jpeg" alt="Fig2" style="width:100%">
    <figcaption>Fig.1: Timelines</figcaption>
</figure>

<figure>
    <img src="./PaxosProof/PaxosProof.008.jpeg" alt="Fig4" style="width:80%">
    <figcaption>Fig.2: Example of computation in rounds</figcaption>
</figure>



<h4 class="w3-text-teal">Learners</h4>
The algorithm for learners is simple:
A learner determines that the consensus value is <code>V</code> if the
learner receives <code>accept(T, V)</code> messages from a majority of
acceptors with identical values of <code>(T, V)</code>.
We ignore learners in the algorithm description, and restrict
attention to whether and when a majority of
acceptors sends <code>accept(T, V)</code> messages with identical
values of <code>(T, V)</code>.

<!--Start Footer--------------------------------------->

    <hr class="new1">
      <p>K. Mani Chandy,
      Emeritus Simon Ramo Professor,
      California Institute of Technology</p>
    
</footer>
    


<!-- END MAIN -->
</div>


</body>
</html>
